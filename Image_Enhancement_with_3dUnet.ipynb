{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fdc69b",
   "metadata": {},
   "source": [
    "# Image Enhancement by 3DUnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895ffb3",
   "metadata": {},
   "source": [
    "## Install environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7635f2",
   "metadata": {},
   "source": [
    "- Create conda environment from environment.yaml by following command: ```conda env create -f environment.yml```\n",
    "\n",
    "- Activate environment \n",
    "```conda activate 3dunet```\n",
    "\n",
    "- Install pytorch-3dunet, following instructions from https://github.com/wolny/pytorch-3dunet.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1bdbb",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df594a",
   "metadata": {},
   "source": [
    "The input data should be 3D images stored in tif files, with dimension order (Z,Y,X). Establish separate folders for the training, validation, and test datasets. For training and validation, it should contain two sub-folders to store raw images and groundtruth data, and an extra folder to store weights if train with ```PixelWiseCrossEntropyLoss``` (see https://github.com/wolny/pytorch-3dunet/blob/2eaf45a49828229b2bf6fd9bba01519a339d3067/README.md). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ef786",
   "metadata": {},
   "source": [
    "## Configuration File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7cf775",
   "metadata": {},
   "source": [
    "Before performing training and test, prepare the configuration files in yaml format. See ```train_config.yaml``` and ```test_config.yaml``` included. \n",
    "- In train_config.yaml\n",
    "  - define the directory to save the model weights through \"trainer: checkpoint_dir:\"\n",
    "  - set the directory to training and validation data, through ```loaders:train:file_paths``` and ```loaders:test:file_paths``` seperately\n",
    "  - set ```loaders:raw_internal_path``` as the subfolder storing of raw images, \n",
    "  - set ```loaders:label_internal_path``` as the subfolder storing ground_truth images\n",
    "  - set ```loaders:weight_internal_path:``` as the subfolder storing weights files (if weights are used). It's null as default.\n",
    "  \n",
    "- In test_config.yaml\n",
    "  - set the path to model file through ```model_path```\n",
    "  - set the path to save result files through ```output_dir```\n",
    "  - set the path to test files through ```test:file_paths```\n",
    "  - In ```slice_builder```：\n",
    "      - ```stride_shape``` should be no larger than ```patch_shape``` \n",
    "      - ```patch_shape``` and ```stride_shape``` should be the same if using ```halo_shape```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9419f2",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ae797",
   "metadata": {},
   "source": [
    "## Load training config from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1755dd-c524-46e5-9b54-989f260ce7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_regression import train_3dunet_regression, load_config_yaml\n",
    "\n",
    "# Path to config file\n",
    "config_file = \"train_config.yaml\"\n",
    "\n",
    "# Load config\n",
    "config = load_config_yaml(config_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14302942",
   "metadata": {},
   "source": [
    "## Visualize Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1ed28",
   "metadata": {},
   "source": [
    "### Visualize raw images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ef7e6",
   "metadata": {},
   "source": [
    "Read image array from tif file and visualize them\n",
    "\n",
    "- Give the path to dataset folder, such as \"path/to/dataset\"\n",
    "- Use TIFDataset.load_dataset_files() to load all tif files in the dataset, retuern a list of [(raw_image_file, groundtruth_file_path, weight_file_path(optional)), ...\n",
    "- Choose the file to visualize by given the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad94d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "from visualize import display_sequence\n",
    "from dataloader import TIFDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b56aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Visualize following files: \n",
      "\t/Users/w.zhao/Projects/MemSeg/Dataset/raw_memb/train/raw_images/201223_RL57M_pos1.tif\n",
      "\t/Users/w.zhao/Projects/MemSeg/Dataset/raw_memb/train/ground_truth/201223_RL57M_pos1_gt.tif\n",
      "- Image shape \n",
      "\t raw image: (64, 406, 406) \n",
      "\t Gt image (64, 406, 406)\n"
     ]
    }
   ],
   "source": [
    "# get config for data loaders\n",
    "config_loaders = config['loaders']\n",
    "\n",
    "# Get image file paths from config\n",
    "train_file_path = config_loaders['train']['file_paths'][0]\n",
    "file_paths = TIFDataset.load_dataset_files(train_file_path)\n",
    "\n",
    "# Uncomment following lines to print all files \n",
    "# for rf, gf, _ in file_paths:\n",
    "#     print(f\"*---{rf}\\n |--{gf}\")\n",
    "\n",
    "# Choose a file to visualize \n",
    "# get image path \n",
    "raw_file_path = file_paths[0][0]\n",
    "# get groundtruth file path\n",
    "gt_file_path = file_paths[0][1]\n",
    "print(f\"- Visualize following files: \\n\\t{raw_file_path}\\n\\t{gt_file_path}\")\n",
    "\n",
    "# read image data\n",
    "raw_im_arr = tifffile.imread(raw_file_path)\n",
    "gt_im_arr = tifffile.imread(gt_file_path)\n",
    "\n",
    "print(f\"- Image shape \\n\\t raw image: {raw_im_arr.shape} \\n\\t Gt image {gt_im_arr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ba70999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f11931da56a4af8bab8c9e819801bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='frame', max=63), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_sequence.<locals>._show(frame=(0, 63))>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize 3d image\n",
    "display_sequence(raw_im_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddffedb",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "- Use train_3dunet_regression to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_regression import train_3dunet_regression\n",
    "\n",
    "\n",
    "# Start to train\n",
    "train_3dunet_regression(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029ab7d",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6db5e3",
   "metadata": {},
   "source": [
    "Load config for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1748ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config_file_path = \"test_config.yaml\"\n",
    "test_config = load_config_yaml(test_config_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aec26b",
   "metadata": {},
   "source": [
    " Use ```predict``` to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_regression import predict\n",
    "\n",
    "predict(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dunet",
   "language": "python",
   "name": "3dunet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
