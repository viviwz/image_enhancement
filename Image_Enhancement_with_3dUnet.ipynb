{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fdc69b",
   "metadata": {},
   "source": [
    "# Train 3DUnet for Image Enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7635f2",
   "metadata": {},
   "source": [
    "- Create conda environment from environment.yaml by following command: ```conda env create -f environment.yml```\n",
    "\n",
    "- Activate environment \n",
    "```conda activate 3dunet```\n",
    "\n",
    "- Install pytorch-3dunet, following instructions from https://github.com/wolny/pytorch-3dunet.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a379fc3",
   "metadata": {},
   "source": [
    "## Load config\n",
    "\n",
    "You need to make the config file in yaml for training and test \n",
    "\n",
    "Some parameters in train_config.yaml:\n",
    "- checkpoint_dir: path to save the trained model\n",
    "- train: filepath: \n",
    "\n",
    "   path to the dataset. Each dataset is a folder includs (possibly) 3 subfolders, one subfolder (\"raw_iamges\") for store all raw images, one folder (\"ground_truth\") to store all groundtruth images, one folder (\"weights\") to store pixel weights if using weigths. For training dataset: \"raw_images\" and \"groundtruth\" are necessory, \"weights\" is optional. For test dataset: only \"raw_images\" is mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f1755dd-c524-46e5-9b54-989f260ce7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_regression import train_3dunet_regression, load_config_yaml\n",
    "\n",
    "# Path to config file\n",
    "config_file = \"train_config.yaml\"\n",
    "\n",
    "# Load config\n",
    "config = load_config_yaml(config_file)\n",
    "\n",
    "# get config for data loaders\n",
    "config_loaders = config['loaders']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14302942",
   "metadata": {},
   "source": [
    "# Visualize Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1ed28",
   "metadata": {},
   "source": [
    "### Visualize raw images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ef7e6",
   "metadata": {},
   "source": [
    "Read image array from tif file and visualize them\n",
    "\n",
    "- Give the path to dataset folder, such as \"path/to/dataset\"\n",
    "- Use TIFDataset.load_dataset_files() to load all tif files in the dataset, retuern a list of [(raw_image_file, groundtruth_file_path, weight_file_path(optional)), ...\n",
    "- Choose the file to visualize by given the index. Print all files using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ad94d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "from visualize import display_sequence\n",
    "from dataloader import TIFDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b56aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Visualize following files: \n",
      "\t/Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/raw_images/201223_RL57M_pos1.tif\n",
      "\t/Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/ground_truth/201223_RL57M_pos1_gt.tif\n",
      "- Image shape \n",
      "\t raw image: (64, 406, 406) \n",
      "\t Gt image (64, 406, 406)\n"
     ]
    }
   ],
   "source": [
    "# Get image file paths  \n",
    "train_file_path = config_loaders['train']['file_paths'][0]\n",
    "file_paths = TIFDataset.load_dataset_files(train_file_path)\n",
    "\n",
    "# Uncomment following lines to print all files \n",
    "# for rf, gf, _ in file_paths:\n",
    "#     print(f\"*---{rf}\\n |--{gf}\")\n",
    "\n",
    "# Choose a file to visualize \n",
    "# get image path \n",
    "raw_file_path = file_paths[0][0]\n",
    "gt_file_path = file_paths[0][1]\n",
    "print(f\"- Visualize following files: \\n\\t{raw_file_path}\\n\\t{gt_file_path}\")\n",
    "\n",
    "# read image data\n",
    "raw_im_arr = tifffile.imread(raw_file_path)\n",
    "gt_im_arr = tifffile.imread(gt_file_path)\n",
    "\n",
    "print(f\"- Image shape \\n\\t raw image: {raw_im_arr.shape} \\n\\t Gt image {gt_im_arr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ba70999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9505881f9ad4d34825b97b8d871f2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='frame', max=63), Output()), _dom_classes=('widget-interâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function visualize.display_sequence.<locals>._show(frame=(0, 63))>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize 3d image\n",
    "display_sequence(raw_im_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddffedb",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "- Use train_3dunet_regression to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b3b6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-19 10:41:14,282 [MainThread] INFO UNetTrainer - Number of learnable params 4119227\n",
      "2024-04-19 10:41:14,282 [MainThread] INFO TIFDataset - Creating training and validation set loaders...\n",
      "2024-04-19 10:41:14,283 [MainThread] INFO TIFDataset - Loading train set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/raw_images/201223_RL57M_pos1.tif...\n",
      "2024-04-19 10:41:14,299 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [32, 32, 32]}\n",
      "2024-04-19 10:41:14,299 [MainThread] INFO TIFDataset - Number of patches: 300\n",
      "2024-04-19 10:41:14,300 [MainThread] INFO TIFDataset - Loading train set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/raw_images/201223_RL57M_pos2.tif...\n",
      "2024-04-19 10:41:14,315 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [32, 32, 32]}\n",
      "2024-04-19 10:41:14,315 [MainThread] INFO TIFDataset - Number of patches: 300\n",
      "2024-04-19 10:41:14,316 [MainThread] INFO TIFDataset - Loading train set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/raw_images/201223_RL57M_pos3.tif...\n",
      "2024-04-19 10:41:14,330 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [32, 32, 32]}\n",
      "2024-04-19 10:41:14,331 [MainThread] INFO TIFDataset - Number of patches: 300\n",
      "2024-04-19 10:41:14,331 [MainThread] INFO TIFDataset - Loading train set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/raw_images/201223_RL57M_pos4.tif...\n",
      "2024-04-19 10:41:14,346 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [32, 32, 32]}\n",
      "2024-04-19 10:41:14,347 [MainThread] INFO TIFDataset - Number of patches: 300\n",
      "2024-04-19 10:41:14,347 [MainThread] INFO TIFDataset - Loading train set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/raw_images/201223_RL57M_pos5.tif...\n",
      "2024-04-19 10:41:14,362 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [32, 32, 32]}\n",
      "2024-04-19 10:41:14,362 [MainThread] INFO TIFDataset - Number of patches: 300\n",
      "2024-04-19 10:41:14,363 [MainThread] INFO TIFDataset - Loading train set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/raw_images/201223_RL57M_pos6.tif...\n",
      "2024-04-19 10:41:14,378 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [32, 32, 32]}\n",
      "2024-04-19 10:41:14,378 [MainThread] INFO TIFDataset - Number of patches: 300\n",
      "2024-04-19 10:41:14,379 [MainThread] INFO TIFDataset - Loading train set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/raw_images/201223_RL57M_pos7.tif...\n",
      "2024-04-19 10:41:14,390 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [32, 32, 32]}\n",
      "2024-04-19 10:41:14,391 [MainThread] INFO TIFDataset - Number of patches: 200\n",
      "2024-04-19 10:41:14,392 [MainThread] INFO TIFDataset - Loading train set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/train/raw_images/201223_RL57M_pos8.tif...\n",
      "2024-04-19 10:41:14,408 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [32, 32, 32]}\n",
      "2024-04-19 10:41:14,409 [MainThread] INFO TIFDataset - Number of patches: 300\n",
      "2024-04-19 10:41:14,412 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos1.tif...\n",
      "2024-04-19 10:41:14,431 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,432 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,432 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos10.tif...\n",
      "2024-04-19 10:41:14,449 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,450 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,450 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos2.tif...\n",
      "2024-04-19 10:41:14,469 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,470 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,471 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos3.tif...\n",
      "2024-04-19 10:41:14,489 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,490 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,491 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos4.tif...\n",
      "2024-04-19 10:41:14,511 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,511 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,512 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos5.tif...\n",
      "2024-04-19 10:41:14,530 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,531 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,531 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos6.tif...\n",
      "2024-04-19 10:41:14,550 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,551 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,551 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos7.tif...\n",
      "2024-04-19 10:41:14,560 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,561 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,561 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos8.tif...\n",
      "2024-04-19 10:41:14,577 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,577 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,578 [MainThread] INFO TIFDataset - Loading val set from: /Users/w.zhao/Projects/MemSeg/Dataset/dataset01/val/raw_images/201223_RL57M_pos9.tif...\n",
      "2024-04-19 10:41:14,595 [MainThread] INFO Dataset - Slice builder config: {'name': 'SliceBuilder', 'patch_shape': [16, 128, 128], 'stride_shape': [128, 128, 128]}\n",
      "2024-04-19 10:41:14,595 [MainThread] INFO TIFDataset - Number of patches: 32\n",
      "2024-04-19 10:41:14,596 [MainThread] INFO TIFDataset - Number of workers for train/val dataloader: 4\n",
      "2024-04-19 10:41:14,596 [MainThread] INFO TIFDataset - Batch size for train/val loader: 1\n",
      "2024-04-19 10:41:14,972 [MainThread] INFO UNetTrainer - UNet3D(\n",
      "  (encoders): ModuleList(\n",
      "    (0): Encoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (groupnorm): GroupNorm(1, 1, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (upsampling): InterpolateUpsampling()\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (upsampling): InterpolateUpsampling()\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Decoder(\n",
      "      (upsampling): InterpolateUpsampling()\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Decoder(\n",
      "      (upsampling): InterpolateUpsampling()\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(48, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      ")\n",
      "2024-04-19 10:41:14,972 [MainThread] INFO UNetTrainer - eval_score_higher_is_better: True\n",
      "2024-04-19 10:41:17,617 [MainThread] INFO UNetTrainer - Training iteration [1/100]. Epoch [0/0]\n",
      "2024-04-19 10:41:18,432 [MainThread] INFO UNetTrainer - Training iteration [2/100]. Epoch [0/0]\n",
      "2024-04-19 10:41:19,137 [MainThread] INFO UNetTrainer - Training iteration [3/100]. Epoch [0/0]\n",
      "2024-04-19 10:41:19,838 [MainThread] INFO UNetTrainer - Training iteration [4/100]. Epoch [0/0]\n",
      "2024-04-19 10:41:20,537 [MainThread] INFO UNetTrainer - Training iteration [5/100]. Epoch [0/0]\n",
      "2024-04-19 10:41:21,227 [MainThread] INFO UNetTrainer - Training iteration [6/100]. Epoch [0/0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Start to train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_3dunet_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/image_enhancement/train_regression.py:35\u001b[0m, in \u001b[0;36mtrain_3dunet_regression\u001b[0;34m(config, config_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m     copy_config(config, config_path)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/3dunet/lib/python3.9/site-packages/pytorch3dunet-1.8.7-py3.9.egg/pytorch3dunet/unet3d/trainer.py:151\u001b[0m, in \u001b[0;36mUNetTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_epochs):\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m         should_terminate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m should_terminate:\n\u001b[1;32m    154\u001b[0m             logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStopping criterion is satisfied. Finishing training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/3dunet/lib/python3.9/site-packages/pytorch3dunet-1.8.7-py3.9.egg/pytorch3dunet/unet3d/trainer.py:184\u001b[0m, in \u001b[0;36mUNetTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# compute gradients and update parameters\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 184\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iterations \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_after_iters \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# set the model in eval mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/3dunet/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/3dunet/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start to train\n",
    "train_3dunet_regression(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029ab7d",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dunet",
   "language": "python",
   "name": "3dunet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
